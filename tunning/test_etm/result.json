{"dataset_name": "dataset_name", "dataset_path": "pl_3723_2019", "is_cached": false, "kernel": "1**2 * Matern(length_scale=1, nu=1.5)", "acq_func": "LCB", "surrogate_model": "RF", "optimization_type": "Maximize", "model_runs": 3, "save_models": true, "save_step": 1, "save_name": "result", "save_path": "tunning/test_etm//", "early_stop": false, "early_step": 5, "plot_model": false, "plot_best_seen": false, "plot_name": "B0_plot", "log_scale_plot": false, "search_space": {"optimizer": ["Categorical", ["adam", "adadelta", "asgd", "adagrad", "sgd", "rmsprop"], null], "t_hidden_size": ["Integer", [400, 1000], "uniform"], "rho": ["Integer", [200, 600], "uniform"], "num_neurons": ["Categorical", [200, 100, 300], null], "activation": ["Categorical", ["sigmoid", "relu", "softplus"], null], "dropout": ["Real", [0.0, 0.95], "uniform"]}, "model_name": "ETM", "model_attributes": {"num_topics": 10, "num_epochs": 100, "rho_size": 300, "embedding_size": 300, "activation": "relu", "dropout": 0.4467841703814587, "lr": 0.005, "optimizer": "adagrad", "batch_size": 128, "clip": 0.0, "wdecay": 1.2e-06, "bow_norm": 1, "train_embeddings": true, "embeddings_type": "pickle", "binary_embeddings": true, "headerless_embeddings": false}, "use_partitioning": true, "metric_name": "Coherence", "extra_metric_names": ["0_TopicDiversity"], "metric_attributes": {"measure": "c_npmi", "topk": 10}, "extra_metric_attributes": {"0_TopicDiversity": {"topk": 10}}, "current_call": 49, "number_of_call": 50, "random_state": 42, "x0": {}, "y0": [], "n_random_starts": 1, "initial_point_generator": "lhs", "topk": 10, "time_eval": [2.2993319034576416, 2.2842438220977783, 5.737467527389526, 17.73689579963684, 15.94709849357605, 19.42136549949646, 77.60800623893738, 13.898767471313477, 14.853049278259277, 15.779573678970337, 32.76047325134277, 13.852275609970093, 13.670603275299072, 13.987606048583984, 12.733481645584106, 6.563264846801758, 6.056567430496216, 6.671865940093994, 6.705500841140747, 7.227544546127319, 9.310374975204468, 6.854450225830078, 8.241111516952515, 7.235163450241089, 7.55867862701416, 8.401081323623657, 6.890438079833984, 7.46985125541687, 7.786729097366333, 14.118100881576538, 5.992918491363525, 3.805563449859619, 4.639127969741821, 4.488046646118164, 4.6126790046691895, 4.4410719871521, 4.303063631057739, 10.918254613876343, 33.08549356460571, 10.16149640083313, 10.592243909835815, 11.115231275558472, 18.12029504776001, 13.268705129623413, 9.458417177200317, 40.74982786178589, 7.140462875366211, 7.503404855728149, 7.709096670150757, 7.224845886230469], "dict_model_runs": {"Coherence": {"iteration_0": [0.029823949184887354, 0.034933569236636854, 0.034933569236636854], "iteration_1": [0.03663677592055335, 0.02982394918488736, 0.02812074250097086], "iteration_2": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_3": [-0.45710120136356186, -0.4342938538958717, -0.46566488130021905], "iteration_4": [-0.4362771326264815, -0.46690103618620304, -0.4555853989237516], "iteration_5": [-0.459104624934261, -0.46288326752934034, -0.4823027975472998], "iteration_6": [-0.504090360778197, -0.527831712116043, -0.5284100218329384], "iteration_7": [0.034933569236636854, 0.03663677592055335, 0.03663677592055335], "iteration_8": [0.033230362552720355, 0.03152715586880385, 0.034933569236636854], "iteration_9": [0.034933569236636854, 0.033230362552720355, 0.026417535817054354], "iteration_10": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_11": [0.03663677592055335, 0.03152715586880385, 0.03663677592055335], "iteration_12": [0.034933569236636854, 0.03663677592055335, 0.033230362552720355], "iteration_13": [0.034933569236636854, 0.02982394918488736, 0.03663677592055335], "iteration_14": [0.03663677592055336, 0.034933569236636854, 0.03663677592055335], "iteration_15": [0.02301112244922136, 0.033230362552720355, 0.03663677592055335], "iteration_16": [0.03663677592055335, 0.031527155868803856, 0.03663677592055335], "iteration_17": [0.03663677592055335, 0.03663677592055335, 0.02812074250097086], "iteration_18": [0.026417535817054354, 0.031527155868803856, 0.034933569236636854], "iteration_19": [0.03663677592055335, 0.034933569236636854, 0.031527155868803856], "iteration_20": [0.03663677592055335, 0.03323036255272035, 0.03152715586880385], "iteration_21": [0.033154596458080735, 0.02964679265493499, 0.03480576392926349], "iteration_22": [0.03663677592055335, 0.03663677592055335, 0.034933569236636854], "iteration_23": [0.03663677592055335, 0.03323036255272035, 0.034933569236636854], "iteration_24": [0.03663677592055335, 0.033230362552720355, 0.033230362552720355], "iteration_25": [0.02812074250097086, 0.029823949184887354, 0.033230362552720355], "iteration_26": [0.034933569236636854, 0.03493356923663686, 0.02812074250097086], "iteration_27": [0.03663677592055335, 0.033230362552720355, 0.034933569236636854], "iteration_28": [0.034933569236636854, 0.03493356923663686, 0.03493356923663686], "iteration_29": [0.02471432913313786, 0.03323036255272035, 0.03663677592055335], "iteration_30": [0.03323036255272036, 0.03152715586880385, 0.034933569236636854], "iteration_31": [0.03663677592055335, 0.03152715586880385, 0.031527155868803856], "iteration_32": [0.034933569236636854, 0.03152715586880385, 0.029823949184887354], "iteration_33": [0.033230362552720355, 0.033230362552720355, 0.02982394918488735], "iteration_34": [0.034933569236636854, 0.03663677592055335, 0.037039125657978865], "iteration_35": [0.034933569236636854, 0.03663677592055335, 0.037039125657978865], "iteration_36": [0.034933569236636854, 0.03192950560622937, 0.03663677592055335], "iteration_37": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_38": [-0.4726023881230554, -0.48016281862315574, -0.45995546588743536], "iteration_39": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_40": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_41": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_42": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_43": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_44": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_45": [-0.46299027458297504, -0.4501529055545831, -0.42876207170741526], "iteration_46": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_47": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_48": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "iteration_49": [0.03663677592055335, 0.03663677592055335, 0.03663677592055335]}, "0_TopicDiversity": {"iteration_0": [0.11, 0.11, 0.11], "iteration_1": [0.1, 0.11, 0.11], "iteration_2": [0.1, 0.1, 0.1], "iteration_3": [0.79, 0.74, 0.85], "iteration_4": [0.78, 0.8, 0.8], "iteration_5": [0.82, 0.8, 0.87], "iteration_6": [0.94, 0.9, 0.94], "iteration_7": [0.11, 0.1, 0.1], "iteration_8": [0.11, 0.11, 0.11], "iteration_9": [0.11, 0.11, 0.11], "iteration_10": [0.1, 0.1, 0.1], "iteration_11": [0.1, 0.11, 0.1], "iteration_12": [0.11, 0.1, 0.11], "iteration_13": [0.11, 0.11, 0.1], "iteration_14": [0.1, 0.11, 0.1], "iteration_15": [0.11, 0.11, 0.1], "iteration_16": [0.1, 0.11, 0.1], "iteration_17": [0.1, 0.1, 0.11], "iteration_18": [0.11, 0.11, 0.11], "iteration_19": [0.1, 0.11, 0.11], "iteration_20": [0.1, 0.11, 0.11], "iteration_21": [0.15, 0.12, 0.12], "iteration_22": [0.1, 0.1, 0.11], "iteration_23": [0.1, 0.11, 0.11], "iteration_24": [0.1, 0.11, 0.11], "iteration_25": [0.11, 0.11, 0.11], "iteration_26": [0.11, 0.11, 0.11], "iteration_27": [0.1, 0.11, 0.11], "iteration_28": [0.11, 0.11, 0.11], "iteration_29": [0.11, 0.11, 0.1], "iteration_30": [0.11, 0.11, 0.11], "iteration_31": [0.1, 0.11, 0.11], "iteration_32": [0.11, 0.11, 0.11], "iteration_33": [0.11, 0.11, 0.11], "iteration_34": [0.11, 0.1, 0.11], "iteration_35": [0.11, 0.1, 0.11], "iteration_36": [0.11, 0.11, 0.1], "iteration_37": [0.1, 0.1, 0.1], "iteration_38": [0.82, 0.84, 0.78], "iteration_39": [0.1, 0.1, 0.1], "iteration_40": [0.1, 0.1, 0.1], "iteration_41": [0.1, 0.1, 0.1], "iteration_42": [0.1, 0.1, 0.1], "iteration_43": [0.1, 0.1, 0.1], "iteration_44": [0.1, 0.1, 0.1], "iteration_45": [0.81, 0.76, 0.8], "iteration_46": [0.1, 0.1, 0.1], "iteration_47": [0.1, 0.1, 0.1], "iteration_48": [0.1, 0.1, 0.1], "iteration_49": [0.1, 0.1, 0.1]}}, "f_val": [0.034933569236636854, 0.02982394918488736, 0.03663677592055335, -0.45710120136356186, -0.4555853989237516, -0.46288326752934034, -0.527831712116043, 0.03663677592055335, 0.033230362552720355, 0.033230362552720355, 0.03663677592055335, 0.03663677592055335, 0.034933569236636854, 0.034933569236636854, 0.03663677592055335, 0.033230362552720355, 0.03663677592055335, 0.03663677592055335, 0.031527155868803856, 0.034933569236636854, 0.03323036255272035, 0.033154596458080735, 0.03663677592055335, 0.034933569236636854, 0.033230362552720355, 0.029823949184887354, 0.034933569236636854, 0.034933569236636854, 0.03493356923663686, 0.03323036255272035, 0.03323036255272036, 0.031527155868803856, 0.03152715586880385, 0.033230362552720355, 0.03663677592055335, 0.03663677592055335, 0.034933569236636854, 0.03663677592055335, -0.4726023881230554, 0.03663677592055335, 0.03663677592055335, 0.03663677592055335, 0.03663677592055335, 0.03663677592055335, 0.03663677592055335, -0.4501529055545831, 0.03663677592055335, 0.03663677592055335, 0.03663677592055335, 0.03663677592055335], "x_iters": {"activation": ["sigmoid", "softplus", "sigmoid", "relu", "relu", "softplus", "relu", "softplus", "softplus", "softplus", "softplus", "relu", "relu", "relu", "relu", "relu", "relu", "relu", "relu", "sigmoid", "relu", "softplus", "relu", "softplus", "relu", "softplus", "relu", "relu", "softplus", "relu", "relu", "relu", "relu", "relu", "sigmoid", "sigmoid", "softplus", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "sigmoid", "softplus", "softplus", "relu", "softplus", "relu", "softplus", "relu", "relu"], "dropout": [0.7910004306992118, 0.7055276827236003, 0.10758064728209163, 0.7059910105556867, 0.1491902882463336, 0.6018485711554749, 0.48344183183714706, 0.7971577036976643, 0.8534211605460501, 0.06027170862982962, 0.45998215807227255, 0.8774204846812496, 0.47622022685107135, 0.8512552716640474, 0.4808491060937611, 0.4929616309406006, 0.4653361731422256, 0.6483706270878878, 0.23627368679669877, 0.08380852678125006, 0.02301755071721594, 0.10672840547228434, 0.8932883335298065, 0.137321069262152, 0.8813766825494721, 0.1922623593268611, 0.15388926362007077, 0.13309613513898164, 0.6932633263329043, 0.41950616096387927, 0.10751832611458476, 0.6135857902292569, 0.03478426229058284, 0.48798718411317, 0.49826590314226615, 0.6591956984432034, 0.5377824024890956, 0.4688409506945342, 0.44689637859077436, 0.21968983901494943, 0.2754585810419658, 0.39090228296915724, 0.46034940233523247, 0.521751923564554, 0.6366124992234696, 0.31871199572549025, 0.6575375035247816, 0.8374404871888983, 0.4924672776489187, 0.4467841703814587], "n_topics": [10, 30, 20, 40, 10, 20, 30, 20, 20, 20, 20, 10, 40, 40, 10, 40, 40, 10, 20, 30, 30, 30, 30, 40, 30, 30, 20, 20, 30, 20, 40, 30, 40, 10, 30, 10, 10, 30, 20, 10, 10, 20, 10, 20, 10, 10, 40, 20, 10, 30], "num_neurons": [200, 200, 300, 300, 300, 200, 100, 200, 200, 200, 300, 100, 100, 100, 300, 100, 100, 300, 300, 300, 200, 300, 100, 300, 200, 200, 100, 300, 200, 200, 300, 100, 100, 200, 300, 300, 300, 300, 300, 300, 100, 100, 100, 100, 300, 100, 100, 300, 100, 100], "optimizer": ["adam", "adam", "adagrad", "asgd", "sgd", "sgd", "adadelta", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adam", "adagrad", "sgd", "adagrad", "adagrad", "adagrad", "adagrad", "adagrad", "adagrad", "asgd", "adagrad", "adagrad", "adagrad", "adagrad"], "rho": [319, 555, 270, 538, 344, 386, 253, 280, 242, 205, 235, 235, 257, 536, 595, 587, 559, 368, 387, 239, 332, 347, 594, 313, 252, 448, 566, 240, 544, 290, 255, 220, 255, 588, 561, 389, 517, 306, 311, 281, 274, 220, 223, 243, 226, 226, 248, 437, 452, 228], "t_hidden_size": [527, 546, 905, 490, 578, 781, 699, 448, 456, 540, 754, 632, 888, 725, 478, 697, 704, 789, 600, 490, 452, 937, 829, 422, 812, 564, 423, 856, 587, 768, 565, 515, 942, 770, 746, 711, 474, 965, 790, 980, 955, 939, 919, 848, 834, 871, 407, 412, 465, 429]}}